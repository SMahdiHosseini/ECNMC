{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import configparser\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import anderson\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (40, 20)\n",
    "plt.rcParams.update({\n",
    "    \"lines.color\": \"black\",\n",
    "    \"patch.edgecolor\": \"black\",\n",
    "    \"text.color\": \"black\",\n",
    "    \"axes.facecolor\": \"white\",\n",
    "    \"axes.edgecolor\": \"black\",\n",
    "    \"axes.labelcolor\": \"black\",\n",
    "    \"xtick.color\": \"black\",\n",
    "    \"ytick.color\": \"black\",\n",
    "    \"grid.color\": \"gray\",\n",
    "    \"figure.facecolor\": \"white\",\n",
    "    \"figure.edgecolor\": \"white\",\n",
    "    \"savefig.facecolor\": \"white\",\n",
    "    \"savefig.edgecolor\": \"white\",\n",
    "    \"font.size\": 30,\n",
    "    \"xtick.labelsize\":30,\n",
    "    \"ytick.labelsize\":30,\n",
    "    \"lines.linewidth\":1.,\n",
    "    \"legend.fontsize\": 10,\n",
    "    })\n",
    "\n",
    "__ns3_path = os.popen('locate \"ns-3.41\" | grep /ns-3.41$').read().splitlines()[0]\n",
    "sample_rate = 0.01\n",
    "confidenceValue = 1.96 # 95% confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert strings like \"2Mbps\" to float\n",
    "def convert_to_float(x):\n",
    "    if 'Mbps' in x:\n",
    "        return float(x[:-4])\n",
    "    elif 'Kbps' in x:\n",
    "        return float(x[:-4]) / 1000\n",
    "    elif 'Gbps' in x:\n",
    "        return float(x[:-4]) * 1000\n",
    "    elif 'ms' in x:\n",
    "        return float(x[:-2])\n",
    "    elif 'us' in x:\n",
    "        return float(x[:-2]) / 1000\n",
    "    else:\n",
    "        return float(x)\n",
    "    \n",
    "def sample_data(data, sample_column):\n",
    "    exit = False\n",
    "    while not exit:\n",
    "        # option 1: sample data with a fixed rate\n",
    "        data_copy = data.sample(frac=sample_rate).sort_values(by=[sample_column])\n",
    "        \n",
    "        # option 2: sample data with a poisson process. Pick the closest packet to the arrival time\n",
    "        # interArrivals = np.random.exponential(1/poisson_sample_rate, int(duration * poisson_sample_rate)) * 1000000000\n",
    "        # interArrivals = np.cumsum(interArrivals)\n",
    "        # interArrivals  = interArrivals + steadyStart * 1000000000\n",
    "        # interArrivals = interArrivals[interArrivals > steadyStart * 1000000000]\n",
    "        # interArrivals = interArrivals[interArrivals < steadyEnd * 1000000000]\n",
    "        # data_copy = pd.DataFrame()\n",
    "        # for i in range(len(interArrivals)):\n",
    "        #     data_copy = pd.concat([data_copy, data.iloc[(data[sample_column] - interArrivals[i]).abs().argsort()[:1]]])\n",
    "\n",
    "        # option 3: sample data with a poisson process. Pick the packets based on the exp distribution not the arrival time\n",
    "        # exps = np.random.exponential(1/poisson_sample_rate, len(data))\n",
    "        # c = np.abs(exps - 1/poisson_sample_rate) / (1/poisson_sample_rate) < 0.01\n",
    "        # data_copy = data.copy()\n",
    "        # data_copy['IsSample'] = c\n",
    "        # data_copy = data_copy[data_copy['IsSample'] == True]\n",
    "        # data_copy = data_copy.sort_values(by=[sample_column])\n",
    "\n",
    "\n",
    "        data_copy['InterArrivalTime'] = data_copy[sample_column].diff()\n",
    "        data_copy = data_copy.dropna().reset_index(drop=True)\n",
    "        anderson_statistic, anderson_critical_values, _ = anderson(data_copy['InterArrivalTime'], 'expon')\n",
    "        if anderson_statistic < anderson_critical_values[2]:\n",
    "            # print('Anderson-Darling test passed')\n",
    "            exit = True\n",
    "    return data_copy.drop(columns=['InterArrivalTime'])\n",
    "\n",
    "def get_switch_samples_delays(flowIndicatorDf, switchDf):\n",
    "    l_df = flowIndicatorDf.copy()\n",
    "    l_df = pd.merge(l_df, switchDf, on=['SourceIp', 'SourcePort', 'DestinationIp', 'DestinationPort', 'PayloadSize', 'SequenceNb'], how='right')\n",
    "    l_df['ReceiveTime'] = l_df['ReceiveTime'].fillna(l_df['SampleTime'])\n",
    "    l_df['SentTime'] = l_df['SentTime'].fillna(l_df['DepartTime'])\n",
    "    return l_df\n",
    "\n",
    "def switch_data(flowIndicatorDf, switchDf, sampling):\n",
    "    l_df = flowIndicatorDf.copy()\n",
    "    l_df = pd.merge(l_df, switchDf, on=['SourceIp', 'SourcePort', 'DestinationIp', 'DestinationPort', 'PayloadSize', 'SequenceNb'], how='inner')\n",
    "    if sampling:\n",
    "        l_df = sample_data(l_df, 'ReceiveTime')\n",
    "    return l_df\n",
    "\n",
    "def intermediateLink_data(flowIndicatorDf, source, dest):\n",
    "    l_df = flowIndicatorDf.copy()\n",
    "    l_df = pd.merge(l_df, source.drop(columns=['ReceiveTime']), on=['SourceIp', 'SourcePort', 'DestinationIp', 'DestinationPort', 'PayloadSize', 'SequenceNb'], how='inner')\n",
    "    l_df = pd.merge(l_df, dest.drop(columns=['SentTime']), on=['SourceIp', 'SourcePort', 'DestinationIp', 'DestinationPort', 'PayloadSize', 'SequenceNb'], how='inner')\n",
    "    # l_df = sample_data(l_df, 'SentTime')\n",
    "    return l_df\n",
    "\n",
    "def get_delayMean(data):\n",
    "    data['Delay'] = abs(data['ReceiveTime'] - data['SentTime'])\n",
    "    return data['Delay'].mean()\n",
    "\n",
    "def get_delayStd(data):\n",
    "    data['Delay'] = abs(data['ReceiveTime'] - data['SentTime'])\n",
    "    return data['Delay'].std()\n",
    "\n",
    "def get_statistics(data):\n",
    "    statistics = {}\n",
    "    statistics['DelayMean'] = get_delayMean(data)\n",
    "    statistics['DelayStd'] = get_delayStd(data)\n",
    "    statistics['sampleSize'] = len(data)\n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ECNMC(endToEnd_delayMean, sumOfSegments_DelayMeans, endToEnd_delayStd, MinSampleSize, confidenceValue):\n",
    "    if abs(endToEnd_delayMean - sumOfSegments_DelayMeans) <= confidenceValue * (endToEnd_delayStd / np.sqrt(MinSampleSize)):\n",
    "        return True\n",
    "    else:  \n",
    "        return False\n",
    "\n",
    "def ECNMC_V2(endToEnd_delayMean, sumOfSegments_DelayMeans, maxEpsilon):\n",
    "    if abs(endToEnd_delayMean - sumOfSegments_DelayMeans) / endToEnd_delayMean <= maxEpsilon:\n",
    "        return True\n",
    "    else:  \n",
    "        return False\n",
    "    \n",
    "def check_single_delayConsistency(endToEnd_statistics, switches_statistics, interLinks_statistics, confidenceValue):\n",
    "    switches_delayMeans = [value['DelayMean'] for value in switches_statistics.values()]\n",
    "    interLinks_delaymeans = [value['DelayMean'] for value in interLinks_statistics.values()]\n",
    "    switches_sampleSizes = [value['sampleSize'] for value in switches_statistics.values()]\n",
    "    MinSampleSize = min(switches_sampleSizes)\n",
    "    sumOfSegmentsDelayMeans = sum(switches_delayMeans + interLinks_delaymeans)\n",
    "\n",
    "    return ECNMC(endToEnd_statistics['DelayMean'], sumOfSegmentsDelayMeans, endToEnd_statistics['DelayStd'], MinSampleSize, confidenceValue)\n",
    "        \n",
    "def check_single_delayConsistency_V2(endToEnd_statistics, switches_statistics, interLinks_statistics, confidenceValue):\n",
    "    # calculate the epsilon = confidenceValue * (switches_delayStd / (sqrt(switches_sampleSize) * switches_delayMean)) for each switch\n",
    "    switches_delayMeans = [value['DelayMean'] for value in switches_statistics.values()]\n",
    "    switches_delayStds = [value['DelayStd'] for value in switches_statistics.values()]\n",
    "    switches_sampleSizes = [value['sampleSize'] for value in switches_statistics.values()]\n",
    "    interLinks_delaymeans = [value['DelayMean'] for value in interLinks_statistics.values()]\n",
    "    interLinks_delayStds = [value['DelayStd'] for value in interLinks_statistics.values()]\n",
    "    interLinks_sampleSizes = [value['sampleSize'] for value in interLinks_statistics.values()]\n",
    "\n",
    "    segments_delayMeans = switches_delayMeans + interLinks_delaymeans\n",
    "    segments_delayStds = switches_delayStds + interLinks_delayStds\n",
    "    segments_sampleSizes = switches_sampleSizes + interLinks_sampleSizes\n",
    "\n",
    "    epsilons = [confidenceValue * (segments_delayStds[i] / (np.sqrt(segments_sampleSizes[i]) * segments_delayMeans[i])) for i in range(len(segments_delayMeans))]\n",
    "    maxEpsilon = max(epsilons)\n",
    "    sumOfSegmentsDelayMeans = sum(segments_delayMeans)\n",
    "\n",
    "    return ECNMC_V2(endToEnd_statistics['DelayMean'], sumOfSegmentsDelayMeans, maxEpsilon)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def check_all_delayConsistency(endToEnd_statistics, switches_statistics, interLinks_statistics, confidenceValue):\n",
    "    res = {}\n",
    "    res['DominantAssumption'] = {}\n",
    "    res['General'] = {}\n",
    "    for flow in endToEnd_statistics.keys():\n",
    "        # print(\"Flow: {}\\n Result: {}\".format(flow, \n",
    "        #                                               check_single_delayConsistency(endToEnd_statistics[flow], switches_statistics[flow], interLinks_statistics[flow], confidenceValue)))\n",
    "        res['DominantAssumption'][flow] = check_single_delayConsistency(endToEnd_statistics[flow], switches_statistics[flow], interLinks_statistics[flow], confidenceValue)\n",
    "        res['General'][flow] = check_single_delayConsistency_V2(endToEnd_statistics[flow], switches_statistics[flow], interLinks_statistics[flow], confidenceValue)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AppKey:\n",
    "    def __init__(self, sourceIp, sourcePort, destIp, destPort):\n",
    "        self.sourceIp = sourceIp\n",
    "        self.sourcePort = sourcePort\n",
    "        self.destIp = destIp\n",
    "        self.destPort = destPort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hostToTorLinkRate:  50.0  Mbps\n",
      "torToAggLinkRate:  40Mbps\n",
      "aggToCoreLinkRate:  50.0  Mbps\n",
      "hostToTorLinkDelay:  3.0  ms\n",
      "torToAggLinkDelay:  3.0  ms\n",
      "aggToCoreLinkDelay:  3.0  ms\n",
      "pctPacedBack:  0.8  %\n",
      "appDataRate:  50.0  Mbps\n",
      "duration:  10.0  s\n",
      "steadyStart:  2.0  s\n",
      "steadyEnd:  9.0  s\n",
      "sampleRate 1000.0\n",
      "experiments:  50\n"
     ]
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('Parameters.config')\n",
    "hostToTorLinkRate = convert_to_float(config.get('Settings', 'hostToTorLinkRate'))\n",
    "torToAggLinkRate = config.get('Settings', 'torToAggLinkRate')\n",
    "aggToCoreLinkRate = convert_to_float(config.get('Settings', 'aggToCoreLinkRate'))\n",
    "hostToTorLinkDelay = convert_to_float(config.get('Settings', 'hostToTorLinkDelay'))\n",
    "torToAggLinkDelay = convert_to_float(config.get('Settings', 'torToAggLinkDelay'))\n",
    "aggToCoreLinkDelay = convert_to_float(config.get('Settings', 'aggToCoreLinkDelay'))\n",
    "pctPacedBack = convert_to_float(config.get('Settings', 'pctPacedBack'))\n",
    "appDataRate = convert_to_float(config.get('Settings', 'appDataRate'))\n",
    "duration = convert_to_float(config.get('Settings', 'duration'))\n",
    "steadyStart = convert_to_float(config.get('Settings', 'steadyStart'))\n",
    "steadyEnd = convert_to_float(config.get('Settings', 'steadyEnd'))\n",
    "sampleRate = convert_to_float(config.get('Settings', 'sampleRate'))\n",
    "experiments = int(config.get('Settings', 'experiments'))\n",
    "\n",
    "print(\"hostToTorLinkRate: \", hostToTorLinkRate, \" Mbps\")\n",
    "print(\"torToAggLinkRate: \", torToAggLinkRate)\n",
    "print(\"aggToCoreLinkRate: \", aggToCoreLinkRate, \" Mbps\")\n",
    "print(\"hostToTorLinkDelay: \", hostToTorLinkDelay, \" ms\")\n",
    "print(\"torToAggLinkDelay: \", torToAggLinkDelay, \" ms\")\n",
    "print(\"aggToCoreLinkDelay: \", aggToCoreLinkDelay, \" ms\")\n",
    "print(\"pctPacedBack: \", pctPacedBack, \" %\")\n",
    "print(\"appDataRate: \", appDataRate, \" Mbps\")\n",
    "print(\"duration: \", duration, \" s\")\n",
    "print(\"steadyStart: \", steadyStart, \" s\")\n",
    "print(\"steadyEnd: \", steadyEnd, \" s\")\n",
    "print(\"sampleRate\", sampleRate)\n",
    "print(\"experiments: \", experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/mahdi/Documents/ns-allinone-3.41/ns-3.41/scratch/Results/40Mbps/0/R0h1R1h1_EndToEnd.csv', '/home/mahdi/Documents/ns-allinone-3.41/ns-3.41/scratch/Results/40Mbps/0/R0h0R1h0_EndToEnd.csv']\n",
      "14147\n",
      "14975\n"
     ]
    }
   ],
   "source": [
    "file_paths = glob.glob('{}/scratch/Results/{}/0/*_EndToEnd.csv'.format(__ns3_path, torToAggLinkRate))\n",
    "endToEnd_dfs = {}\n",
    "apps = []\n",
    "print(file_paths)\n",
    "for file_path in file_paths:\n",
    "    df_name = file_path.split('/')[-1].split('_')[0]\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df[df['IsReceived'] == 1]\n",
    "    df = df.reset_index(drop=True)\n",
    "    # df['EndToEndDelay'] = (df['ReceiveTime'] - df['SentTime'])\n",
    "    # keep the packets their sent time is after 1s\n",
    "    df = df[df['SentTime'] > steadyStart * 1000000000]\n",
    "    df = df[df['SentTime'] < steadyEnd * 1000000000]\n",
    "    # df = df.drop(columns=['IsReceived', 'ReceiveTime', 'SentTime'])\n",
    "    df = df.drop(columns=['IsReceived'])\n",
    "    print(len(df))\n",
    "    endToEnd_dfs[df_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29120\n",
      "29167\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceIp</th>\n",
       "      <th>SourcePort</th>\n",
       "      <th>DestinationIp</th>\n",
       "      <th>DestinationPort</th>\n",
       "      <th>SequenceNb</th>\n",
       "      <th>PayloadSize</th>\n",
       "      <th>ReceiveTime</th>\n",
       "      <th>SentTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>10.1.2.1</td>\n",
       "      <td>49553</td>\n",
       "      <td>10.2.2.1</td>\n",
       "      <td>6618</td>\n",
       "      <td>10095</td>\n",
       "      <td>1442</td>\n",
       "      <td>4577575760</td>\n",
       "      <td>4650618480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>10.1.2.1</td>\n",
       "      <td>49462</td>\n",
       "      <td>10.2.2.1</td>\n",
       "      <td>6902</td>\n",
       "      <td>152041</td>\n",
       "      <td>1448</td>\n",
       "      <td>4577336400</td>\n",
       "      <td>4650318080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>10.1.1.1</td>\n",
       "      <td>49732</td>\n",
       "      <td>10.2.1.1</td>\n",
       "      <td>4510</td>\n",
       "      <td>56197</td>\n",
       "      <td>1448</td>\n",
       "      <td>8279620293</td>\n",
       "      <td>8365572680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>10.1.1.1</td>\n",
       "      <td>49567</td>\n",
       "      <td>10.2.1.1</td>\n",
       "      <td>4148</td>\n",
       "      <td>39627</td>\n",
       "      <td>1448</td>\n",
       "      <td>4574990800</td>\n",
       "      <td>4647918480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>10.1.1.1</td>\n",
       "      <td>49709</td>\n",
       "      <td>10.2.1.1</td>\n",
       "      <td>4361</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4574637280</td>\n",
       "      <td>4647906880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SourceIp  SourcePort DestinationIp  DestinationPort  SequenceNb  \\\n",
       "370  10.1.2.1       49553      10.2.2.1             6618       10095   \n",
       "372  10.1.2.1       49462      10.2.2.1             6902      152041   \n",
       "373  10.1.1.1       49732      10.2.1.1             4510       56197   \n",
       "374  10.1.1.1       49567      10.2.1.1             4148       39627   \n",
       "375  10.1.1.1       49709      10.2.1.1             4361           0   \n",
       "\n",
       "     PayloadSize  ReceiveTime    SentTime  \n",
       "370         1442   4577575760  4650618480  \n",
       "372         1448   4577336400  4650318080  \n",
       "373         1448   8279620293  8365572680  \n",
       "374         1448   4574990800  4647918480  \n",
       "375            0   4574637280  4647906880  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths = glob.glob('{}/scratch/Results/{}/0/*_Switch.csv'.format(__ns3_path, torToAggLinkRate))\n",
    "switch_dfs = {}\n",
    "\n",
    "for file_path in file_paths:\n",
    "    df_name = file_path.split('/')[-1].split('_')[0]\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df[df['IsSent'] == 1]\n",
    "    df = df.reset_index(drop=True)\n",
    "    # df['SegmentDelay'] = (df['SentTime'] - df['ReceiveTime'])\n",
    "    # keep the packets their sent time is after 1s\n",
    "    df = df[df['ReceiveTime'] > steadyStart * 1000000000]\n",
    "    df = df[df['ReceiveTime'] < steadyEnd * 1000000000]\n",
    "    # drop IsReceived, SourcePort, DestinationPort, SequenceNb, ReceiveTime, SentTime\n",
    "    df = df.drop(columns=['IsSent'])\n",
    "    print(len(df))\n",
    "    switch_dfs[df_name] = df\n",
    "\n",
    "switch_dfs[list(switch_dfs.keys())[0]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6979\n",
      "6937\n",
      "7027\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceIp</th>\n",
       "      <th>SourcePort</th>\n",
       "      <th>DestinationIp</th>\n",
       "      <th>DestinationPort</th>\n",
       "      <th>SequenceNb</th>\n",
       "      <th>PayloadSize</th>\n",
       "      <th>SampleTime</th>\n",
       "      <th>DepartTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>10.1.1.1</td>\n",
       "      <td>49158</td>\n",
       "      <td>10.2.1.1</td>\n",
       "      <td>5421</td>\n",
       "      <td>443429</td>\n",
       "      <td>1442</td>\n",
       "      <td>8997400225</td>\n",
       "      <td>9068033280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>10.1.1.1</td>\n",
       "      <td>49551</td>\n",
       "      <td>10.2.1.1</td>\n",
       "      <td>5535</td>\n",
       "      <td>546</td>\n",
       "      <td>154</td>\n",
       "      <td>8996294801</td>\n",
       "      <td>9067107680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>10.1.2.1</td>\n",
       "      <td>49400</td>\n",
       "      <td>10.2.2.1</td>\n",
       "      <td>6291</td>\n",
       "      <td>175687</td>\n",
       "      <td>1158</td>\n",
       "      <td>8995013841</td>\n",
       "      <td>9065964080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>10.1.1.1</td>\n",
       "      <td>49412</td>\n",
       "      <td>10.2.1.1</td>\n",
       "      <td>4231</td>\n",
       "      <td>77612</td>\n",
       "      <td>1448</td>\n",
       "      <td>8992706890</td>\n",
       "      <td>9063939680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>10.1.2.1</td>\n",
       "      <td>49177</td>\n",
       "      <td>10.2.2.1</td>\n",
       "      <td>6583</td>\n",
       "      <td>739878</td>\n",
       "      <td>1448</td>\n",
       "      <td>8987852931</td>\n",
       "      <td>9058084680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SourceIp  SourcePort DestinationIp  DestinationPort  SequenceNb  \\\n",
       "397  10.1.1.1       49158      10.2.1.1             5421      443429   \n",
       "398  10.1.1.1       49551      10.2.1.1             5535         546   \n",
       "399  10.1.2.1       49400      10.2.2.1             6291      175687   \n",
       "400  10.1.1.1       49412      10.2.1.1             4231       77612   \n",
       "401  10.1.2.1       49177      10.2.2.1             6583      739878   \n",
       "\n",
       "     PayloadSize  SampleTime  DepartTime  \n",
       "397         1442  8997400225  9068033280  \n",
       "398          154  8996294801  9067107680  \n",
       "399         1158  8995013841  9065964080  \n",
       "400         1448  8992706890  9063939680  \n",
       "401         1448  8987852931  9058084680  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths = glob.glob('{}/scratch/Results/{}/0/*_PoissonSampler.csv'.format(__ns3_path, torToAggLinkRate))\n",
    "samples_dfs = {}\n",
    "\n",
    "for file_path in file_paths:\n",
    "    df_name = file_path.split('/')[-1].split('_')[0]\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df[df['IsDeparted'] == 1]\n",
    "    df = df.reset_index(drop=True)\n",
    "    # keep the packets their sent time is after 1s\n",
    "    df = df[df['SampleTime'] > steadyStart * 1000000000]\n",
    "    df = df[df['SampleTime'] < steadyEnd * 1000000000]\n",
    "    df = df.drop(columns=['IsDeparted'])\n",
    "    print(len(df))\n",
    "    samples_dfs[df_name] = df\n",
    "\n",
    "samples_dfs[list(samples_dfs.keys())[0]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate links groundtruth statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R0h1R1h1': {('source', 'T0'): {'DelayMean': 3383676.0856314525,\n",
       "   'DelayStd': 396970.1572164474,\n",
       "   'sampleSize': 14142},\n",
       "  ('T0', 'T1'): {'DelayMean': 3246152.0788684096,\n",
       "   'DelayStd': 103022.89644473646,\n",
       "   'sampleSize': 13998},\n",
       "  ('T1', 'dest'): {'DelayMean': 3196921.663094728,\n",
       "   'DelayStd': 82418.31715578918,\n",
       "   'sampleSize': 13998}},\n",
       " 'R0h0R1h0': {('source', 'T0'): {'DelayMean': 3386371.4898095555,\n",
       "   'DelayStd': 403668.1122212889,\n",
       "   'sampleSize': 14965},\n",
       "  ('T0', 'T1'): {'DelayMean': 3234430.6009453074,\n",
       "   'DelayStd': 109813.04549680691,\n",
       "   'sampleSize': 14810},\n",
       "  ('T1', 'dest'): {'DelayMean': 3187544.4807562456,\n",
       "   'DelayStd': 87850.43639744553,\n",
       "   'sampleSize': 14810}}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interLinks_statistics = {}\n",
    "for flow in endToEnd_dfs.keys():\n",
    "    interLinks_statistics[flow] = {}\n",
    "    interLinks_statistics[flow][('source', 'T0')] = get_statistics(intermediateLink_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), endToEnd_dfs[flow], switch_dfs['T0']))\n",
    "    interLinks_statistics[flow][('T0', 'T1')] = get_statistics(intermediateLink_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T0'], switch_dfs['T1']))\n",
    "    interLinks_statistics[flow][('T1', 'dest')] = get_statistics(intermediateLink_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T1'], endToEnd_dfs[flow]))\n",
    "\n",
    "interLinks_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Switches statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Overall': {'R0h1R1h1': {'T0': {'DelayMean': 76575476.48115776,\n",
       "    'DelayStd': 12924779.782883303,\n",
       "    'sampleSize': 6979},\n",
       "   'T1': {'DelayMean': 9228.23395474598,\n",
       "    'DelayStd': 42742.23044440099,\n",
       "    'sampleSize': 7027}},\n",
       "  'R0h0R1h0': {'T0': {'DelayMean': 76575476.48115776,\n",
       "    'DelayStd': 12924779.782883303,\n",
       "    'sampleSize': 6979},\n",
       "   'T1': {'DelayMean': 10233.213204555283,\n",
       "    'DelayStd': 44839.13601317457,\n",
       "    'sampleSize': 6937}}},\n",
       " 'PerTrafficStream': {'R0h1R1h1': {'T0': {'DelayMean': 75988454.41428572,\n",
       "    'DelayStd': 12240918.849862361,\n",
       "    'sampleSize': 140},\n",
       "   'T1': {'DelayMean': 19589.928057553956,\n",
       "    'DelayStd': 60559.148251534294,\n",
       "    'sampleSize': 139}},\n",
       "  'R0h0R1h0': {'T0': {'DelayMean': 77484193.30872484,\n",
       "    'DelayStd': 12465850.253691847,\n",
       "    'sampleSize': 149},\n",
       "   'T1': {'DelayMean': 19104.48979591837,\n",
       "    'DelayStd': 58528.68903347858,\n",
       "    'sampleSize': 147}}}}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_statistics = {}\n",
    "samples_statistics['Overall'] = {}\n",
    "samples_statistics['PerTrafficStream'] = {}\n",
    "\n",
    "for flow in endToEnd_dfs.keys():\n",
    "    samples_statistics['Overall'][flow] = {}\n",
    "    samples_statistics['Overall'][flow]['T0'] = get_statistics(get_switch_samples_delays(switch_dfs['T0'], samples_dfs['T0T1']))\n",
    "    samples_statistics['Overall'][flow]['T1'] = get_statistics(get_switch_samples_delays(switch_dfs['T1'], samples_dfs['T1.R' + flow.split('R')[-1]]))\n",
    "\n",
    "    samples_statistics['PerTrafficStream'][flow] = {}\n",
    "    samples_statistics['PerTrafficStream'][flow]['T0'] = get_statistics(switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T0'], True))\n",
    "    samples_statistics['PerTrafficStream'][flow]['T1'] = get_statistics(switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T1'], True))\n",
    "\n",
    "samples_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Overall': {'R0h1R1h1': {'T0': {'DelayMean': 76577644.9568338,\n",
       "    'DelayStd': 12831059.773091657,\n",
       "    'sampleSize': 29120},\n",
       "   'T1': {'DelayMean': 26948.539102410257,\n",
       "    'DelayStd': 67909.75897065419,\n",
       "    'sampleSize': 29167}},\n",
       "  'R0h0R1h0': {'T0': {'DelayMean': 76577644.9568338,\n",
       "    'DelayStd': 12831059.773091657,\n",
       "    'sampleSize': 29120},\n",
       "   'T1': {'DelayMean': 26948.539102410257,\n",
       "    'DelayStd': 67909.75897065419,\n",
       "    'sampleSize': 29167}}},\n",
       " 'PerTrafficStream': {'R0h1R1h1': {'T0': {'DelayMean': 76350267.90609533,\n",
       "    'DelayStd': 12879666.22516689,\n",
       "    'sampleSize': 14142},\n",
       "   'T1': {'DelayMean': 24508.644092013146,\n",
       "    'DelayStd': 65367.715453827506,\n",
       "    'sampleSize': 13998}},\n",
       "  'R0h0R1h0': {'T0': {'DelayMean': 76792301.64122954,\n",
       "    'DelayStd': 12787261.127092661,\n",
       "    'sampleSize': 14965},\n",
       "   'T1': {'DelayMean': 29216.197164078327,\n",
       "    'DelayStd': 70144.78696893422,\n",
       "    'sampleSize': 14810}}}}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundtruth_statistics = {}\n",
    "groundtruth_statistics['Overall'] = {}\n",
    "groundtruth_statistics['PerTrafficStream'] = {}\n",
    "\n",
    "for flow in endToEnd_dfs.keys():\n",
    "    groundtruth_statistics['Overall'][flow] = {}\n",
    "    groundtruth_statistics['Overall'][flow]['T0'] = get_statistics(switch_dfs['T0'])\n",
    "    groundtruth_statistics['Overall'][flow]['T1'] = get_statistics(switch_dfs['T1'])\n",
    "\n",
    "    groundtruth_statistics['PerTrafficStream'][flow] = {}\n",
    "    groundtruth_statistics['PerTrafficStream'][flow]['T0'] = get_statistics(switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T0'], False))\n",
    "    groundtruth_statistics['PerTrafficStream'][flow]['T1'] = get_statistics(switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T1'], False))\n",
    "\n",
    "groundtruth_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Anova Test for the delays of the segments\n",
    "# temp = {}\n",
    "# for flow in endToEnd_dfs.keys():\n",
    "#     temp[flow] = {}\n",
    "#     temp[flow]['T0'] = switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T0'])\n",
    "#     temp[flow]['T0']['Delay'] = abs(temp[flow]['T0']['ReceiveTime'] - temp[flow]['T0']['SentTime'])\n",
    "\n",
    "# # test if for T0, the delays of all flow are from the same distribution with ANova test\n",
    "# from scipy.stats import f_oneway\n",
    "# f_oneway(*[temp[flow]['T0']['Delay'] for flow in endToEnd_dfs.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the delay distribution of SWitch T0 and Sample T0\n",
    "# fig, ax = plt.subplots(1, 2)\n",
    "# l_df = get_switch_samples_delays(switch_dfs['T0'], samples_dfs['T0T1'])\n",
    "# # l2_df = switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T0'])\n",
    "# l2_df = switch_dfs['T0']\n",
    "# sns.histplot(l_df['SentTime'] - l_df['ReceiveTime'], ax=ax[0])\n",
    "# sns.histplot(l2_df['SentTime'] - l2_df['ReceiveTime'], ax=ax[1])\n",
    "# ax[0].set_title('Sample T0')\n",
    "# ax[1].set_title('Switch T0')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the delay distribution of SWitch T0 for all flows and the aggregated delay distribution\n",
    "# fig, ax = plt.subplots()\n",
    "# for flow in endToEnd_dfs.keys():\n",
    "#     l_df = switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T0'])\n",
    "#     sns.histplot(l_df['SentTime'] - l_df['ReceiveTime'], label=flow)\n",
    "#     ax.set_title('Switch T0')\n",
    "# # l_df = switch_dfs['T0']\n",
    "# # sns.histplot(l_df['SentTime'] - l_df['ReceiveTime'], ax=ax[1])\n",
    "# # ax[1].set_title('Switch T0')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groundtruth delay mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R0h1R1h1': {'DelayMean': 86199379.77154167, 'DelayStd': 12879099.461896347, 'sampleSize': 14147}, 'R0h0R1h0': {'DelayMean': 86625367.43525876, 'DelayStd': 12768922.633258518, 'sampleSize': 14975}}\n"
     ]
    }
   ],
   "source": [
    "# calculate the mean and std of thet delay of each flow\n",
    "endToEnd_statistics = {}\n",
    "for flow in endToEnd_dfs.keys():\n",
    "    # endToEnd_statistics[flow] = get_statistics(sample_data(endToEnd_dfs[flow], 'SentTime'))\n",
    "    endToEnd_statistics[flow] = get_statistics(endToEnd_dfs[flow])\n",
    "\n",
    "print(endToEnd_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to End and Persegment Compatibility Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Overall': {'groundtruth': {'DominantAssumption': {'R0h1R1h1': False,\n",
       "    'R0h0R1h0': False},\n",
       "   'General': {'R0h1R1h1': True, 'R0h0R1h0': True}},\n",
       "  'samples': {'DominantAssumption': {'R0h1R1h1': True, 'R0h0R1h0': True},\n",
       "   'General': {'R0h1R1h1': True, 'R0h0R1h0': True}}},\n",
       " 'PerTrafficStream': {'groundtruth': {'DominantAssumption': {'R0h1R1h1': True,\n",
       "    'R0h0R1h0': True},\n",
       "   'General': {'R0h1R1h1': True, 'R0h0R1h0': True}},\n",
       "  'samples': {'DominantAssumption': {'R0h1R1h1': True, 'R0h0R1h0': True},\n",
       "   'General': {'R0h1R1h1': True, 'R0h0R1h0': True}}}}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "results['Overall'] = {}\n",
    "results['PerTrafficStream'] = {}\n",
    "results['Overall']['groundtruth'] = check_all_delayConsistency(endToEnd_statistics, groundtruth_statistics['Overall'], interLinks_statistics, confidenceValue)\n",
    "results['Overall']['samples'] = check_all_delayConsistency(endToEnd_statistics, samples_statistics['Overall'], interLinks_statistics, confidenceValue)\n",
    "results['PerTrafficStream']['groundtruth'] = check_all_delayConsistency(endToEnd_statistics, groundtruth_statistics['PerTrafficStream'], interLinks_statistics, confidenceValue)\n",
    "results['PerTrafficStream']['samples'] = check_all_delayConsistency(endToEnd_statistics, samples_statistics['PerTrafficStream'], interLinks_statistics, confidenceValue)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat sampling to check if the relation holds more than 95% of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Overall': {'groundtruth': {'DominantAssumption': {'R0h1R1h1': 28, 'R0h0R1h0': 31}, 'General': {'R0h1R1h1': 50, 'R0h0R1h0': 50}}, 'samples': {'DominantAssumption': {'R0h1R1h1': 36, 'R0h0R1h0': 37}, 'General': {'R0h1R1h1': 50, 'R0h0R1h0': 50}}}, 'PerTrafficStream': {'groundtruth': {'DominantAssumption': {'R0h1R1h1': 50, 'R0h0R1h0': 50}, 'General': {'R0h1R1h1': 50, 'R0h0R1h0': 50}}, 'samples': {'DominantAssumption': {'R0h1R1h1': 48, 'R0h0R1h0': 50}, 'General': {'R0h1R1h1': 50, 'R0h0R1h0': 50}}}}\n"
     ]
    }
   ],
   "source": [
    "rounds_results = {}\n",
    "rounds_results['Overall'] = {}\n",
    "rounds_results['PerTrafficStream'] = {}\n",
    "rounds_results['Overall']['groundtruth'] = {}\n",
    "rounds_results['Overall']['samples'] = {}\n",
    "rounds_results['PerTrafficStream']['groundtruth'] = {}\n",
    "rounds_results['PerTrafficStream']['samples'] = {}\n",
    "rounds_results['Overall']['groundtruth']['DominantAssumption'] = {}\n",
    "rounds_results['Overall']['groundtruth']['General'] = {}\n",
    "rounds_results['Overall']['samples']['DominantAssumption'] = {}\n",
    "rounds_results['Overall']['samples']['General'] = {}\n",
    "rounds_results['PerTrafficStream']['groundtruth']['DominantAssumption'] = {}\n",
    "rounds_results['PerTrafficStream']['groundtruth']['General'] = {}\n",
    "rounds_results['PerTrafficStream']['samples']['DominantAssumption'] = {}\n",
    "rounds_results['PerTrafficStream']['samples']['General'] = {}\n",
    "for flow in endToEnd_dfs.keys():\n",
    "    rounds_results['Overall']['groundtruth']['DominantAssumption'][flow] = 0\n",
    "    rounds_results['Overall']['groundtruth']['General'][flow] = 0\n",
    "    rounds_results['Overall']['samples']['DominantAssumption'][flow] = 0\n",
    "    rounds_results['Overall']['samples']['General'][flow] = 0\n",
    "    rounds_results['PerTrafficStream']['groundtruth']['DominantAssumption'][flow] = 0\n",
    "    rounds_results['PerTrafficStream']['groundtruth']['General'][flow] = 0\n",
    "    rounds_results['PerTrafficStream']['samples']['DominantAssumption'][flow] = 0\n",
    "    rounds_results['PerTrafficStream']['samples']['General'][flow] = 0\n",
    "\n",
    "for experiment in range(experiments):\n",
    "# for experiment in range(3):\n",
    "    # Reading the Groundtruth\n",
    "    file_paths = glob.glob('{}/scratch/Results/{}/{}/*_EndToEnd.csv'.format(__ns3_path, torToAggLinkRate, experiment))\n",
    "    endToEnd_dfs = {}\n",
    "    for file_path in file_paths:\n",
    "        df_name = file_path.split('/')[-1].split('_')[0]\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df[df['IsReceived'] == 1]\n",
    "        df = df.reset_index(drop=True)\n",
    "        df = df[df['SentTime'] > steadyStart * 1000000000]\n",
    "        df = df[df['SentTime'] < steadyEnd * 1000000000]\n",
    "        df = df.drop(columns=['IsReceived'])\n",
    "        endToEnd_dfs[df_name] = df\n",
    "\n",
    "    file_paths = glob.glob('{}/scratch/Results/{}/{}/*_Switch.csv'.format(__ns3_path, torToAggLinkRate, experiment))\n",
    "    switch_dfs = {}\n",
    "    for file_path in file_paths:\n",
    "        df_name = file_path.split('/')[-1].split('_')[0]\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df[df['IsSent'] == 1]\n",
    "        df = df.reset_index(drop=True)\n",
    "        df = df[df['ReceiveTime'] > steadyStart * 1000000000]\n",
    "        df = df[df['ReceiveTime'] < steadyEnd * 1000000000]\n",
    "        df = df.drop(columns=['IsSent'])\n",
    "        switch_dfs[df_name] = df\n",
    "\n",
    "    # Reading the Samples\n",
    "    file_paths = glob.glob('{}/scratch/Results/{}/{}/*_PoissonSampler.csv'.format(__ns3_path, torToAggLinkRate, experiment))\n",
    "    samples_dfs = {}\n",
    "    for file_path in file_paths:\n",
    "        df_name = file_path.split('/')[-1].split('_')[0]\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df[df['IsDeparted'] == 1]\n",
    "        df = df.reset_index(drop=True)\n",
    "        df = df[df['SampleTime'] > steadyStart * 1000000000]\n",
    "        df = df[df['SampleTime'] < steadyEnd * 1000000000]\n",
    "        df = df.drop(columns=['IsDeparted'])\n",
    "        samples_dfs[df_name] = df\n",
    "\n",
    "    # Intermediate links groundtruth statistics\n",
    "    interLinks_statistics = {}\n",
    "    for flow in endToEnd_dfs.keys():\n",
    "        interLinks_statistics[flow] = {}\n",
    "        interLinks_statistics[flow][('source', 'T0')] = get_statistics(intermediateLink_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), endToEnd_dfs[flow], switch_dfs['T0']))\n",
    "        interLinks_statistics[flow][('T0', 'T1')] = get_statistics(intermediateLink_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T0'], switch_dfs['T1']))\n",
    "        interLinks_statistics[flow][('T1', 'dest')] = get_statistics(intermediateLink_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T1'], endToEnd_dfs[flow]))\n",
    "\n",
    "\n",
    "    # samples switches statistics\n",
    "    samples_statistics = {}\n",
    "    samples_statistics['Overall'] = {}\n",
    "    samples_statistics['PerTrafficStream'] = {}\n",
    "\n",
    "    for flow in endToEnd_dfs.keys():\n",
    "        samples_statistics['Overall'][flow] = {}\n",
    "        samples_statistics['Overall'][flow]['T0'] = get_statistics(get_switch_samples_delays(switch_dfs['T0'], samples_dfs['T0T1']))\n",
    "        samples_statistics['Overall'][flow]['T1'] = get_statistics(get_switch_samples_delays(switch_dfs['T1'], samples_dfs['T1.R' + flow.split('R')[-1]]))\n",
    "\n",
    "        samples_statistics['PerTrafficStream'][flow] = {}\n",
    "        samples_statistics['PerTrafficStream'][flow]['T0'] = get_statistics(switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T0'], True))\n",
    "        samples_statistics['PerTrafficStream'][flow]['T1'] = get_statistics(switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T1'], True))\n",
    "\n",
    "    # groundtruth switches statistics\n",
    "    groundtruth_statistics = {}\n",
    "    groundtruth_statistics['Overall'] = {}\n",
    "    groundtruth_statistics['PerTrafficStream'] = {}\n",
    "\n",
    "    for flow in endToEnd_dfs.keys():\n",
    "        groundtruth_statistics['Overall'][flow] = {}\n",
    "        groundtruth_statistics['Overall'][flow]['T0'] = get_statistics(switch_dfs['T0'])\n",
    "        groundtruth_statistics['Overall'][flow]['T1'] = get_statistics(switch_dfs['T1'])\n",
    "\n",
    "        groundtruth_statistics['PerTrafficStream'][flow] = {}\n",
    "        groundtruth_statistics['PerTrafficStream'][flow]['T0'] = get_statistics(switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T0'], False))\n",
    "        groundtruth_statistics['PerTrafficStream'][flow]['T1'] = get_statistics(switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T1'], False))\n",
    "\n",
    "    # endToEnd_statistics\n",
    "    endToEnd_statistics = {}\n",
    "    for flow in endToEnd_dfs.keys():\n",
    "        endToEnd_statistics[flow] = get_statistics(endToEnd_dfs[flow])\n",
    "\n",
    "    # End to End and Persegment Compatibility Check\n",
    "    results = {}\n",
    "    results['Overall'] = {}\n",
    "    results['PerTrafficStream'] = {}\n",
    "    results['Overall']['groundtruth'] = check_all_delayConsistency(endToEnd_statistics, groundtruth_statistics['Overall'], interLinks_statistics, confidenceValue)\n",
    "    results['Overall']['samples'] = check_all_delayConsistency(endToEnd_statistics, samples_statistics['Overall'], interLinks_statistics, confidenceValue)\n",
    "    results['PerTrafficStream']['groundtruth'] = check_all_delayConsistency(endToEnd_statistics, groundtruth_statistics['PerTrafficStream'], interLinks_statistics, confidenceValue)\n",
    "    results['PerTrafficStream']['samples'] = check_all_delayConsistency(endToEnd_statistics, samples_statistics['PerTrafficStream'], interLinks_statistics, confidenceValue)\n",
    "\n",
    "    for flow in endToEnd_dfs.keys():\n",
    "        if results['Overall']['groundtruth']['DominantAssumption'][flow]:\n",
    "            rounds_results['Overall']['groundtruth']['DominantAssumption'][flow] += 1\n",
    "        if results['Overall']['groundtruth']['General'][flow]:\n",
    "            rounds_results['Overall']['groundtruth']['General'][flow] += 1\n",
    "        if results['Overall']['samples']['DominantAssumption'][flow]:\n",
    "            rounds_results['Overall']['samples']['DominantAssumption'][flow] += 1\n",
    "        if results['Overall']['samples']['General'][flow]:\n",
    "            rounds_results['Overall']['samples']['General'][flow] += 1\n",
    "        if results['PerTrafficStream']['groundtruth']['DominantAssumption'][flow]:\n",
    "            rounds_results['PerTrafficStream']['groundtruth']['DominantAssumption'][flow] += 1\n",
    "        if results['PerTrafficStream']['groundtruth']['General'][flow]:\n",
    "            rounds_results['PerTrafficStream']['groundtruth']['General'][flow] += 1\n",
    "        if results['PerTrafficStream']['samples']['DominantAssumption'][flow]:\n",
    "            rounds_results['PerTrafficStream']['samples']['DominantAssumption'][flow] += 1\n",
    "        if results['PerTrafficStream']['samples']['General'][flow]:\n",
    "            rounds_results['PerTrafficStream']['samples']['General'][flow] += 1\n",
    "\n",
    "# rounds_results\n",
    "# convert the results to jason and save it in results.json\n",
    "import json\n",
    "with open('results/{}_results.json'.format(torToAggLinkRate), 'w') as f:\n",
    "    json.dump(rounds_results, f)\n",
    "print(rounds_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
