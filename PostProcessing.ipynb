{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import configparser\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import anderson\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (40, 20)\n",
    "plt.rcParams.update({\n",
    "    \"lines.color\": \"black\",\n",
    "    \"patch.edgecolor\": \"black\",\n",
    "    \"text.color\": \"black\",\n",
    "    \"axes.facecolor\": \"white\",\n",
    "    \"axes.edgecolor\": \"black\",\n",
    "    \"axes.labelcolor\": \"black\",\n",
    "    \"xtick.color\": \"black\",\n",
    "    \"ytick.color\": \"black\",\n",
    "    \"grid.color\": \"gray\",\n",
    "    \"figure.facecolor\": \"white\",\n",
    "    \"figure.edgecolor\": \"white\",\n",
    "    \"savefig.facecolor\": \"white\",\n",
    "    \"savefig.edgecolor\": \"white\",\n",
    "    \"font.size\": 30,\n",
    "    \"xtick.labelsize\":30,\n",
    "    \"ytick.labelsize\":30,\n",
    "    \"lines.linewidth\":1.,\n",
    "    \"legend.fontsize\": 10,\n",
    "    })\n",
    "\n",
    "__ns3_path = os.popen('locate \"ns-3.41\" | grep /ns-3.41$').read().splitlines()[0]\n",
    "sample_rate = 0.01\n",
    "confidenceValue = 1.96 # 95% confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert strings like \"2Mbps\" to float\n",
    "def convert_to_float(x):\n",
    "    if 'Mbps' in x:\n",
    "        return float(x[:-4])\n",
    "    elif 'Kbps' in x:\n",
    "        return float(x[:-4]) / 1000\n",
    "    elif 'Gbps' in x:\n",
    "        return float(x[:-4]) * 1000\n",
    "    elif 'ms' in x:\n",
    "        return float(x[:-2])\n",
    "    elif 'us' in x:\n",
    "        return float(x[:-2]) / 1000\n",
    "    else:\n",
    "        return float(x)\n",
    "    \n",
    "def sample_data(data, sample_column):\n",
    "    exit = False\n",
    "    while not exit:\n",
    "        # option 1: sample data with a fixed rate\n",
    "        data_copy = data.sample(frac=sample_rate).sort_values(by=[sample_column])\n",
    "        \n",
    "        # option 2: sample data with a poisson process. Pick the closest packet to the arrival time\n",
    "        # interArrivals = np.random.exponential(1/poisson_sample_rate, int(duration * poisson_sample_rate)) * 1000000000\n",
    "        # interArrivals = np.cumsum(interArrivals)\n",
    "        # interArrivals  = interArrivals + steadyStart * 1000000000\n",
    "        # interArrivals = interArrivals[interArrivals > steadyStart * 1000000000]\n",
    "        # interArrivals = interArrivals[interArrivals < steadyEnd * 1000000000]\n",
    "        # data_copy = pd.DataFrame()\n",
    "        # for i in range(len(interArrivals)):\n",
    "        #     data_copy = pd.concat([data_copy, data.iloc[(data[sample_column] - interArrivals[i]).abs().argsort()[:1]]])\n",
    "\n",
    "        # option 3: sample data with a poisson process. Pick the packets based on the exp distribution not the arrival time\n",
    "        # exps = np.random.exponential(1/poisson_sample_rate, len(data))\n",
    "        # c = np.abs(exps - 1/poisson_sample_rate) / (1/poisson_sample_rate) < 0.01\n",
    "        # data_copy = data.copy()\n",
    "        # data_copy['IsSample'] = c\n",
    "        # data_copy = data_copy[data_copy['IsSample'] == True]\n",
    "        # data_copy = data_copy.sort_values(by=[sample_column])\n",
    "\n",
    "\n",
    "        data_copy['InterArrivalTime'] = data_copy[sample_column].diff()\n",
    "        data_copy = data_copy.dropna().reset_index(drop=True)\n",
    "        anderson_statistic, anderson_critical_values, _ = anderson(data_copy['InterArrivalTime'], 'expon')\n",
    "        if anderson_statistic < anderson_critical_values[2]:\n",
    "            # print('Anderson-Darling test passed')\n",
    "            exit = True\n",
    "    return data_copy.drop(columns=['InterArrivalTime'])\n",
    "\n",
    "def get_switch_samples_delays(flowIndicatorDf, switchDf):\n",
    "    l_df = flowIndicatorDf.copy()\n",
    "    l_df = pd.merge(l_df, switchDf, on=['SourceIp', 'SourcePort', 'DestinationIp', 'DestinationPort', 'PayloadSize', 'SequenceNb'], how='right')\n",
    "    l_df['ReceiveTime'] = l_df['ReceiveTime'].fillna(l_df['SampleTime'])\n",
    "    l_df['SentTime'] = l_df['SentTime'].fillna(l_df['DepartTime'])\n",
    "    return l_df\n",
    "\n",
    "def switch_data(flowIndicatorDf, switchDf, sampling):\n",
    "    l_df = flowIndicatorDf.copy()\n",
    "    l_df = pd.merge(l_df, switchDf, on=['SourceIp', 'SourcePort', 'DestinationIp', 'DestinationPort', 'PayloadSize', 'SequenceNb'], how='inner')\n",
    "    if sampling:\n",
    "        l_df = sample_data(l_df, 'ReceiveTime')\n",
    "    return l_df\n",
    "\n",
    "def intermediateLink_data(flowIndicatorDf, source, dest):\n",
    "    l_df = flowIndicatorDf.copy()\n",
    "    l_df = pd.merge(l_df, source.drop(columns=['ReceiveTime']), on=['SourceIp', 'SourcePort', 'DestinationIp', 'DestinationPort', 'PayloadSize', 'SequenceNb'], how='inner')\n",
    "    l_df = pd.merge(l_df, dest.drop(columns=['SentTime']), on=['SourceIp', 'SourcePort', 'DestinationIp', 'DestinationPort', 'PayloadSize', 'SequenceNb'], how='inner')\n",
    "    # l_df = sample_data(l_df, 'SentTime')\n",
    "    return l_df\n",
    "\n",
    "def get_delayMean(data):\n",
    "    data['Delay'] = abs(data['ReceiveTime'] - data['SentTime'])\n",
    "    return data['Delay'].mean()\n",
    "\n",
    "def get_delayStd(data):\n",
    "    data['Delay'] = abs(data['ReceiveTime'] - data['SentTime'])\n",
    "    return data['Delay'].std()\n",
    "\n",
    "def get_statistics(data):\n",
    "    statistics = {}\n",
    "    statistics['DelayMean'] = get_delayMean(data)\n",
    "    statistics['DelayStd'] = get_delayStd(data)\n",
    "    statistics['sampleSize'] = len(data)\n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ECNMC(endToEnd_delayMean, sumOfSegments_DelayMeans, endToEnd_delayStd, MinSampleSize, confidenceValue):\n",
    "    if abs(endToEnd_delayMean - sumOfSegments_DelayMeans) <= confidenceValue * (endToEnd_delayStd / np.sqrt(MinSampleSize)):\n",
    "        return True\n",
    "    else:  \n",
    "        return False\n",
    "\n",
    "def ECNMC_V2(endToEnd_delayMean, sumOfSegments_DelayMeans, maxEpsilon):\n",
    "    if abs(endToEnd_delayMean - sumOfSegments_DelayMeans) / endToEnd_delayMean <= maxEpsilon:\n",
    "        return True\n",
    "    else:  \n",
    "        return False\n",
    "    \n",
    "def check_single_delayConsistency(endToEnd_statistics, switches_statistics, interLinks_statistics, confidenceValue):\n",
    "    switches_delayMeans = [value['DelayMean'] for value in switches_statistics.values()]\n",
    "    interLinks_delaymeans = [value['DelayMean'] for value in interLinks_statistics.values()]\n",
    "    switches_sampleSizes = [value['sampleSize'] for value in switches_statistics.values()]\n",
    "    MinSampleSize = min(switches_sampleSizes)\n",
    "    sumOfSegmentsDelayMeans = sum(switches_delayMeans + interLinks_delaymeans)\n",
    "\n",
    "    return ECNMC(endToEnd_statistics['DelayMean'], sumOfSegmentsDelayMeans, endToEnd_statistics['DelayStd'], MinSampleSize, confidenceValue)\n",
    "        \n",
    "def check_single_delayConsistency_V2(endToEnd_statistics, switches_statistics, interLinks_statistics, confidenceValue):\n",
    "    # calculate the epsilon = confidenceValue * (switches_delayStd / (sqrt(switches_sampleSize) * switches_delayMean)) for each switch\n",
    "    switches_delayMeans = [value['DelayMean'] for value in switches_statistics.values()]\n",
    "    switches_delayStds = [value['DelayStd'] for value in switches_statistics.values()]\n",
    "    switches_sampleSizes = [value['sampleSize'] for value in switches_statistics.values()]\n",
    "    interLinks_delaymeans = [value['DelayMean'] for value in interLinks_statistics.values()]\n",
    "    interLinks_delayStds = [value['DelayStd'] for value in interLinks_statistics.values()]\n",
    "    interLinks_sampleSizes = [value['sampleSize'] for value in interLinks_statistics.values()]\n",
    "\n",
    "    segments_delayMeans = switches_delayMeans + interLinks_delaymeans\n",
    "    segments_delayStds = switches_delayStds + interLinks_delayStds\n",
    "    segments_sampleSizes = switches_sampleSizes + interLinks_sampleSizes\n",
    "\n",
    "    epsilons = [confidenceValue * (segments_delayStds[i] / (np.sqrt(segments_sampleSizes[i]) * segments_delayMeans[i])) for i in range(len(segments_delayMeans))]\n",
    "    maxEpsilon = max(epsilons)\n",
    "    sumOfSegmentsDelayMeans = sum(segments_delayMeans)\n",
    "\n",
    "    return ECNMC_V2(endToEnd_statistics['DelayMean'], sumOfSegmentsDelayMeans, maxEpsilon)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def check_all_delayConsistency(endToEnd_statistics, switches_statistics, interLinks_statistics, confidenceValue):\n",
    "    res = {}\n",
    "    res['DominantAssumption'] = {}\n",
    "    res['General'] = {}\n",
    "    for flow in endToEnd_statistics.keys():\n",
    "        # print(\"Flow: {}\\n Result: {}\".format(flow, \n",
    "        #                                               check_single_delayConsistency(endToEnd_statistics[flow], switches_statistics[flow], interLinks_statistics[flow], confidenceValue)))\n",
    "        res['DominantAssumption'][flow] = check_single_delayConsistency(endToEnd_statistics[flow], switches_statistics[flow], interLinks_statistics[flow], confidenceValue)\n",
    "        res['General'][flow] = check_single_delayConsistency_V2(endToEnd_statistics[flow], switches_statistics[flow], interLinks_statistics[flow], confidenceValue)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AppKey:\n",
    "    def __init__(self, sourceIp, sourcePort, destIp, destPort):\n",
    "        self.sourceIp = sourceIp\n",
    "        self.sourcePort = sourcePort\n",
    "        self.destIp = destIp\n",
    "        self.destPort = destPort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hostToTorLinkRate:  50.0  Mbps\n",
      "torToAggLinkRate:  50.0  Mbps\n",
      "aggToCoreLinkRate:  50.0  Mbps\n",
      "hostToTorLinkDelay:  3.0  ms\n",
      "torToAggLinkDelay:  3.0  ms\n",
      "aggToCoreLinkDelay:  3.0  ms\n",
      "pctPacedBack:  0.8  %\n",
      "appDataRate:  50.0  Mbps\n",
      "duration:  10.0  s\n",
      "steadyStart:  2.0  s\n",
      "steadyEnd:  9.0  s\n",
      "sampleRate 1000.0\n",
      "experiments:  2\n"
     ]
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('Parameters.config')\n",
    "hostToTorLinkRate = convert_to_float(config.get('Settings', 'hostToTorLinkRate'))\n",
    "torToAggLinkRate = convert_to_float(config.get('Settings', 'torToAggLinkRate'))\n",
    "aggToCoreLinkRate = convert_to_float(config.get('Settings', 'aggToCoreLinkRate'))\n",
    "hostToTorLinkDelay = convert_to_float(config.get('Settings', 'hostToTorLinkDelay'))\n",
    "torToAggLinkDelay = convert_to_float(config.get('Settings', 'torToAggLinkDelay'))\n",
    "aggToCoreLinkDelay = convert_to_float(config.get('Settings', 'aggToCoreLinkDelay'))\n",
    "pctPacedBack = convert_to_float(config.get('Settings', 'pctPacedBack'))\n",
    "appDataRate = convert_to_float(config.get('Settings', 'appDataRate'))\n",
    "duration = convert_to_float(config.get('Settings', 'duration'))\n",
    "steadyStart = convert_to_float(config.get('Settings', 'steadyStart'))\n",
    "steadyEnd = convert_to_float(config.get('Settings', 'steadyEnd'))\n",
    "sampleRate = convert_to_float(config.get('Settings', 'sampleRate'))\n",
    "experiments = int(config.get('Settings', 'experiments'))\n",
    "\n",
    "print(\"hostToTorLinkRate: \", hostToTorLinkRate, \" Mbps\")\n",
    "print(\"torToAggLinkRate: \", torToAggLinkRate, \" Mbps\")\n",
    "print(\"aggToCoreLinkRate: \", aggToCoreLinkRate, \" Mbps\")\n",
    "print(\"hostToTorLinkDelay: \", hostToTorLinkDelay, \" ms\")\n",
    "print(\"torToAggLinkDelay: \", torToAggLinkDelay, \" ms\")\n",
    "print(\"aggToCoreLinkDelay: \", aggToCoreLinkDelay, \" ms\")\n",
    "print(\"pctPacedBack: \", pctPacedBack, \" %\")\n",
    "print(\"appDataRate: \", appDataRate, \" Mbps\")\n",
    "print(\"duration: \", duration, \" s\")\n",
    "print(\"steadyStart: \", steadyStart, \" s\")\n",
    "print(\"steadyEnd: \", steadyEnd, \" s\")\n",
    "print(\"sampleRate\", sampleRate)\n",
    "print(\"experiments: \", experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/mahdi/Documents/NAL/ns-allinone-3.41/ns-3.41/scratch/Results/50Mbps/0/R0h1R1h1_EndToEnd.csv', '/home/mahdi/Documents/NAL/ns-allinone-3.41/ns-3.41/scratch/Results/50Mbps/0/R0h0R1h0_EndToEnd.csv']\n",
      "16637\n",
      "19090\n"
     ]
    }
   ],
   "source": [
    "file_paths = glob.glob('{}/scratch/Results/50Mbps/0/*_EndToEnd.csv'.format(__ns3_path))\n",
    "endToEnd_dfs = {}\n",
    "apps = []\n",
    "print(file_paths)\n",
    "for file_path in file_paths:\n",
    "    df_name = file_path.split('/')[-1].split('_')[0]\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df[df['IsReceived'] == 1]\n",
    "    df = df.reset_index(drop=True)\n",
    "    # df['EndToEndDelay'] = (df['ReceiveTime'] - df['SentTime'])\n",
    "    # keep the packets their sent time is after 1s\n",
    "    df = df[df['SentTime'] > steadyStart * 1000000000]\n",
    "    df = df[df['SentTime'] < steadyEnd * 1000000000]\n",
    "    # df = df.drop(columns=['IsReceived', 'ReceiveTime', 'SentTime'])\n",
    "    df = df.drop(columns=['IsReceived'])\n",
    "    print(len(df))\n",
    "    endToEnd_dfs[df_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35771\n",
      "35725\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceIp</th>\n",
       "      <th>SourcePort</th>\n",
       "      <th>DestinationIp</th>\n",
       "      <th>DestinationPort</th>\n",
       "      <th>SequenceNb</th>\n",
       "      <th>PayloadSize</th>\n",
       "      <th>ReceiveTime</th>\n",
       "      <th>SentTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>10.1.2.1</td>\n",
       "      <td>49200</td>\n",
       "      <td>10.2.2.1</td>\n",
       "      <td>7419</td>\n",
       "      <td>144156</td>\n",
       "      <td>1448</td>\n",
       "      <td>8999595066</td>\n",
       "      <td>8999595066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>10.1.1.1</td>\n",
       "      <td>49538</td>\n",
       "      <td>10.2.1.1</td>\n",
       "      <td>4241</td>\n",
       "      <td>766</td>\n",
       "      <td>14</td>\n",
       "      <td>8999354746</td>\n",
       "      <td>8999468026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>10.1.2.1</td>\n",
       "      <td>49222</td>\n",
       "      <td>10.2.2.1</td>\n",
       "      <td>6164</td>\n",
       "      <td>636086</td>\n",
       "      <td>666</td>\n",
       "      <td>8999343866</td>\n",
       "      <td>8999343866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>10.1.1.1</td>\n",
       "      <td>49176</td>\n",
       "      <td>10.2.1.1</td>\n",
       "      <td>4502</td>\n",
       "      <td>187604</td>\n",
       "      <td>1442</td>\n",
       "      <td>8999176826</td>\n",
       "      <td>8999176826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>10.1.2.1</td>\n",
       "      <td>49440</td>\n",
       "      <td>10.2.2.1</td>\n",
       "      <td>7189</td>\n",
       "      <td>24042</td>\n",
       "      <td>359</td>\n",
       "      <td>8998456826</td>\n",
       "      <td>8998456826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SourceIp  SourcePort DestinationIp  DestinationPort  SequenceNb  \\\n",
       "2981  10.1.2.1       49200      10.2.2.1             7419      144156   \n",
       "2982  10.1.1.1       49538      10.2.1.1             4241         766   \n",
       "2984  10.1.2.1       49222      10.2.2.1             6164      636086   \n",
       "2985  10.1.1.1       49176      10.2.1.1             4502      187604   \n",
       "2986  10.1.2.1       49440      10.2.2.1             7189       24042   \n",
       "\n",
       "      PayloadSize  ReceiveTime    SentTime  \n",
       "2981         1448   8999595066  8999595066  \n",
       "2982           14   8999354746  8999468026  \n",
       "2984          666   8999343866  8999343866  \n",
       "2985         1442   8999176826  8999176826  \n",
       "2986          359   8998456826  8998456826  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths = glob.glob('{}/scratch/Results/50Mbps/0/*_Switch.csv'.format(__ns3_path))\n",
    "switch_dfs = {}\n",
    "\n",
    "for file_path in file_paths:\n",
    "    df_name = file_path.split('/')[-1].split('_')[0]\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df[df['IsSent'] == 1]\n",
    "    df = df.reset_index(drop=True)\n",
    "    # df['SegmentDelay'] = (df['SentTime'] - df['ReceiveTime'])\n",
    "    # keep the packets their sent time is after 1s\n",
    "    df = df[df['ReceiveTime'] > steadyStart * 1000000000]\n",
    "    df = df[df['ReceiveTime'] < steadyEnd * 1000000000]\n",
    "    # drop IsReceived, SourcePort, DestinationPort, SequenceNb, ReceiveTime, SentTime\n",
    "    df = df.drop(columns=['IsSent'])\n",
    "    print(len(df))\n",
    "    switch_dfs[df_name] = df\n",
    "\n",
    "switch_dfs[list(switch_dfs.keys())[0]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6979\n",
      "6937\n",
      "7027\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceIp</th>\n",
       "      <th>SourcePort</th>\n",
       "      <th>DestinationIp</th>\n",
       "      <th>DestinationPort</th>\n",
       "      <th>SequenceNb</th>\n",
       "      <th>PayloadSize</th>\n",
       "      <th>SampleTime</th>\n",
       "      <th>DepartTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>10.1.2.1</td>\n",
       "      <td>49668</td>\n",
       "      <td>10.2.2.1</td>\n",
       "      <td>6825</td>\n",
       "      <td>1</td>\n",
       "      <td>1448</td>\n",
       "      <td>8996294801</td>\n",
       "      <td>9047092826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>10.1.2.1</td>\n",
       "      <td>49663</td>\n",
       "      <td>10.2.2.1</td>\n",
       "      <td>6807</td>\n",
       "      <td>34753</td>\n",
       "      <td>1448</td>\n",
       "      <td>8992706890</td>\n",
       "      <td>9042878586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>10.1.2.1</td>\n",
       "      <td>49200</td>\n",
       "      <td>10.2.2.1</td>\n",
       "      <td>7419</td>\n",
       "      <td>148500</td>\n",
       "      <td>411</td>\n",
       "      <td>8987852931</td>\n",
       "      <td>9036949306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>10.1.2.1</td>\n",
       "      <td>49239</td>\n",
       "      <td>10.2.2.1</td>\n",
       "      <td>7269</td>\n",
       "      <td>700027</td>\n",
       "      <td>1448</td>\n",
       "      <td>8987453506</td>\n",
       "      <td>9036708986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>10.1.2.1</td>\n",
       "      <td>49243</td>\n",
       "      <td>10.2.2.1</td>\n",
       "      <td>7287</td>\n",
       "      <td>713454</td>\n",
       "      <td>1448</td>\n",
       "      <td>8987191125</td>\n",
       "      <td>9036468666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SourceIp  SourcePort DestinationIp  DestinationPort  SequenceNb  \\\n",
       "393  10.1.2.1       49668      10.2.2.1             6825           1   \n",
       "394  10.1.2.1       49663      10.2.2.1             6807       34753   \n",
       "395  10.1.2.1       49200      10.2.2.1             7419      148500   \n",
       "396  10.1.2.1       49239      10.2.2.1             7269      700027   \n",
       "397  10.1.2.1       49243      10.2.2.1             7287      713454   \n",
       "\n",
       "     PayloadSize  SampleTime  DepartTime  \n",
       "393         1448  8996294801  9047092826  \n",
       "394         1448  8992706890  9042878586  \n",
       "395          411  8987852931  9036949306  \n",
       "396         1448  8987453506  9036708986  \n",
       "397         1448  8987191125  9036468666  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths = glob.glob('{}/scratch/Results/50Mbps/0/*_PoissonSampler.csv'.format(__ns3_path))\n",
    "samples_dfs = {}\n",
    "\n",
    "for file_path in file_paths:\n",
    "    df_name = file_path.split('/')[-1].split('_')[0]\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df[df['IsDeparted'] == 1]\n",
    "    df = df.reset_index(drop=True)\n",
    "    # keep the packets their sent time is after 1s\n",
    "    df = df[df['SampleTime'] > steadyStart * 1000000000]\n",
    "    df = df[df['SampleTime'] < steadyEnd * 1000000000]\n",
    "    df = df.drop(columns=['IsDeparted'])\n",
    "    print(len(df))\n",
    "    samples_dfs[df_name] = df\n",
    "\n",
    "samples_dfs[list(samples_dfs.keys())[0]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate links groundtruth statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R0h1R1h1': {('source', 'T0'): {'DelayMean': 3414553.4708924703,\n",
       "   'DelayStd': 473713.91394338995,\n",
       "   'sampleSize': 16628},\n",
       "  ('T0', 'T1'): {'DelayMean': 3196272.830577261,\n",
       "   'DelayStd': 79506.29668074592,\n",
       "   'sampleSize': 16509},\n",
       "  ('T1', 'dest'): {'DelayMean': 3196272.830577261,\n",
       "   'DelayStd': 79506.29668074592,\n",
       "   'sampleSize': 16509}},\n",
       " 'R0h0R1h0': {('source', 'T0'): {'DelayMean': 3477290.1963527747,\n",
       "   'DelayStd': 559034.3420664251,\n",
       "   'sampleSize': 19083},\n",
       "  ('T0', 'T1'): {'DelayMean': 3195216.6485229614,\n",
       "   'DelayStd': 82632.2947406187,\n",
       "   'sampleSize': 18923},\n",
       "  ('T1', 'dest'): {'DelayMean': 3195216.6485229614,\n",
       "   'DelayStd': 82632.2947406187,\n",
       "   'sampleSize': 18923}}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interLinks_statistics = {}\n",
    "for flow in endToEnd_dfs.keys():\n",
    "    interLinks_statistics[flow] = {}\n",
    "    interLinks_statistics[flow][('source', 'T0')] = get_statistics(intermediateLink_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), endToEnd_dfs[flow], switch_dfs['T0']))\n",
    "    interLinks_statistics[flow][('T0', 'T1')] = get_statistics(intermediateLink_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T0'], switch_dfs['T1']))\n",
    "    interLinks_statistics[flow][('T1', 'dest')] = get_statistics(intermediateLink_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T1'], endToEnd_dfs[flow]))\n",
    "\n",
    "interLinks_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Switches statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Overall': {'R0h1R1h1': {'T0': {'DelayMean': 54537980.1488752,\n",
       "    'DelayStd': 13694480.42715089,\n",
       "    'sampleSize': 6979},\n",
       "   'T1': {'DelayMean': 10431.808737725914,\n",
       "    'DelayStd': 45075.75800796941,\n",
       "    'sampleSize': 7027}},\n",
       "  'R0h0R1h0': {'T0': {'DelayMean': 54537980.1488752,\n",
       "    'DelayStd': 13694480.42715089,\n",
       "    'sampleSize': 6979},\n",
       "   'T1': {'DelayMean': 14348.865503820096,\n",
       "    'DelayStd': 52920.105069117715,\n",
       "    'sampleSize': 6937}}},\n",
       " 'PerTrafficStream': {'R0h1R1h1': {'T0': {'DelayMean': 52573587.28484848,\n",
       "    'DelayStd': 13835437.17511221,\n",
       "    'sampleSize': 165},\n",
       "   'T1': {'DelayMean': 18635.121951219513,\n",
       "    'DelayStd': 55580.641689889504,\n",
       "    'sampleSize': 164}},\n",
       "  'R0h0R1h0': {'T0': {'DelayMean': 54380686.55789474,\n",
       "    'DelayStd': 13006878.360653859,\n",
       "    'sampleSize': 190},\n",
       "   'T1': {'DelayMean': 27461.27659574468,\n",
       "    'DelayStd': 65397.47181876928,\n",
       "    'sampleSize': 188}}}}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_statistics = {}\n",
    "samples_statistics['Overall'] = {}\n",
    "samples_statistics['PerTrafficStream'] = {}\n",
    "\n",
    "for flow in endToEnd_dfs.keys():\n",
    "    samples_statistics['Overall'][flow] = {}\n",
    "    samples_statistics['Overall'][flow]['T0'] = get_statistics(get_switch_samples_delays(switch_dfs['T0'], samples_dfs['T0T1']))\n",
    "    samples_statistics['Overall'][flow]['T1'] = get_statistics(get_switch_samples_delays(switch_dfs['T1'], samples_dfs['T1.R' + flow.split('R')[-1]]))\n",
    "\n",
    "    samples_statistics['PerTrafficStream'][flow] = {}\n",
    "    samples_statistics['PerTrafficStream'][flow]['T0'] = get_statistics(switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T0'], True))\n",
    "    samples_statistics['PerTrafficStream'][flow]['T1'] = get_statistics(switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T1'], True))\n",
    "\n",
    "samples_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Overall': {'R0h1R1h1': {'T0': {'DelayMean': 54234348.80285514,\n",
       "    'DelayStd': 13609224.596293403,\n",
       "    'sampleSize': 35725},\n",
       "   'T1': {'DelayMean': 28275.060803444132,\n",
       "    'DelayStd': 68902.48939861961,\n",
       "    'sampleSize': 35771}},\n",
       "  'R0h0R1h0': {'T0': {'DelayMean': 54234348.80285514,\n",
       "    'DelayStd': 13609224.596293403,\n",
       "    'sampleSize': 35725},\n",
       "   'T1': {'DelayMean': 28275.060803444132,\n",
       "    'DelayStd': 68902.48939861961,\n",
       "    'sampleSize': 35771}}},\n",
       " 'PerTrafficStream': {'R0h1R1h1': {'T0': {'DelayMean': 54164268.459766656,\n",
       "    'DelayStd': 13546179.823522119,\n",
       "    'sampleSize': 16628},\n",
       "   'T1': {'DelayMean': 26428.0186564904,\n",
       "    'DelayStd': 66447.9473846724,\n",
       "    'sampleSize': 16509}},\n",
       "  'R0h0R1h0': {'T0': {'DelayMean': 54291891.6870513,\n",
       "    'DelayStd': 13668349.575525953,\n",
       "    'sampleSize': 19083},\n",
       "   'T1': {'DelayMean': 29883.64212862654,\n",
       "    'DelayStd': 70970.36885575454,\n",
       "    'sampleSize': 18923}}}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundtruth_statistics = {}\n",
    "groundtruth_statistics['Overall'] = {}\n",
    "groundtruth_statistics['PerTrafficStream'] = {}\n",
    "\n",
    "for flow in endToEnd_dfs.keys():\n",
    "    groundtruth_statistics['Overall'][flow] = {}\n",
    "    groundtruth_statistics['Overall'][flow]['T0'] = get_statistics(switch_dfs['T0'])\n",
    "    groundtruth_statistics['Overall'][flow]['T1'] = get_statistics(switch_dfs['T1'])\n",
    "\n",
    "    groundtruth_statistics['PerTrafficStream'][flow] = {}\n",
    "    groundtruth_statistics['PerTrafficStream'][flow]['T0'] = get_statistics(switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T0'], False))\n",
    "    groundtruth_statistics['PerTrafficStream'][flow]['T1'] = get_statistics(switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T1'], False))\n",
    "\n",
    "groundtruth_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Anova Test for the delays of the segments\n",
    "# temp = {}\n",
    "# for flow in endToEnd_dfs.keys():\n",
    "#     temp[flow] = {}\n",
    "#     temp[flow]['T0'] = switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T0'])\n",
    "#     temp[flow]['T0']['Delay'] = abs(temp[flow]['T0']['ReceiveTime'] - temp[flow]['T0']['SentTime'])\n",
    "\n",
    "# # test if for T0, the delays of all flow are from the same distribution with ANova test\n",
    "# from scipy.stats import f_oneway\n",
    "# f_oneway(*[temp[flow]['T0']['Delay'] for flow in endToEnd_dfs.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the delay distribution of SWitch T0 and Sample T0\n",
    "# fig, ax = plt.subplots(1, 2)\n",
    "# l_df = get_switch_samples_delays(switch_dfs['T0'], samples_dfs['T0T1'])\n",
    "# # l2_df = switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T0'])\n",
    "# l2_df = switch_dfs['T0']\n",
    "# sns.histplot(l_df['SentTime'] - l_df['ReceiveTime'], ax=ax[0])\n",
    "# sns.histplot(l2_df['SentTime'] - l2_df['ReceiveTime'], ax=ax[1])\n",
    "# ax[0].set_title('Sample T0')\n",
    "# ax[1].set_title('Switch T0')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the delay distribution of SWitch T0 for all flows and the aggregated delay distribution\n",
    "# fig, ax = plt.subplots()\n",
    "# for flow in endToEnd_dfs.keys():\n",
    "#     l_df = switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T0'])\n",
    "#     sns.histplot(l_df['SentTime'] - l_df['ReceiveTime'], label=flow)\n",
    "#     ax.set_title('Switch T0')\n",
    "# # l_df = switch_dfs['T0']\n",
    "# # sns.histplot(l_df['SentTime'] - l_df['ReceiveTime'], ax=ax[1])\n",
    "# # ax[1].set_title('Switch T0')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groundtruth delay mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R0h1R1h1': {'DelayMean': 63997046.37729158, 'DelayStd': 13563011.057140183, 'sampleSize': 16637}, 'R0h0R1h0': {'DelayMean': 64189111.16914615, 'DelayStd': 13692861.639190746, 'sampleSize': 19090}}\n"
     ]
    }
   ],
   "source": [
    "# calculate the mean and std of thet delay of each flow\n",
    "endToEnd_statistics = {}\n",
    "for flow in endToEnd_dfs.keys():\n",
    "    # endToEnd_statistics[flow] = get_statistics(sample_data(endToEnd_dfs[flow], 'SentTime'))\n",
    "    endToEnd_statistics[flow] = get_statistics(endToEnd_dfs[flow])\n",
    "\n",
    "print(endToEnd_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to End and Persegment Compatibility Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Overall': {'groundtruth': {'DominantAssumption': {'R0h1R1h1': True,\n",
       "    'R0h0R1h0': True},\n",
       "   'General': {'R0h1R1h1': True, 'R0h0R1h0': True}},\n",
       "  'samples': {'DominantAssumption': {'R0h1R1h1': False, 'R0h0R1h0': True},\n",
       "   'General': {'R0h1R1h1': True, 'R0h0R1h0': True}}},\n",
       " 'PerTrafficStream': {'groundtruth': {'DominantAssumption': {'R0h1R1h1': True,\n",
       "    'R0h0R1h0': True},\n",
       "   'General': {'R0h1R1h1': True, 'R0h0R1h0': True}},\n",
       "  'samples': {'DominantAssumption': {'R0h1R1h1': True, 'R0h0R1h0': True},\n",
       "   'General': {'R0h1R1h1': True, 'R0h0R1h0': True}}}}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "results['Overall'] = {}\n",
    "results['PerTrafficStream'] = {}\n",
    "results['Overall']['groundtruth'] = check_all_delayConsistency(endToEnd_statistics, groundtruth_statistics['Overall'], interLinks_statistics, confidenceValue)\n",
    "results['Overall']['samples'] = check_all_delayConsistency(endToEnd_statistics, samples_statistics['Overall'], interLinks_statistics, confidenceValue)\n",
    "results['PerTrafficStream']['groundtruth'] = check_all_delayConsistency(endToEnd_statistics, groundtruth_statistics['PerTrafficStream'], interLinks_statistics, confidenceValue)\n",
    "results['PerTrafficStream']['samples'] = check_all_delayConsistency(endToEnd_statistics, samples_statistics['PerTrafficStream'], interLinks_statistics, confidenceValue)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat sampling to check if the relation holds more than 95% of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds_results = {}\n",
    "rounds_results['Overall'] = {}\n",
    "rounds_results['PerTrafficStream'] = {}\n",
    "rounds_results['Overall']['groundtruth'] = {}\n",
    "rounds_results['Overall']['samples'] = {}\n",
    "rounds_results['PerTrafficStream']['groundtruth'] = {}\n",
    "rounds_results['PerTrafficStream']['samples'] = {}\n",
    "rounds_results['Overall']['groundtruth']['DominantAssumption'] = {}\n",
    "rounds_results['Overall']['groundtruth']['General'] = {}\n",
    "rounds_results['Overall']['samples']['DominantAssumption'] = {}\n",
    "rounds_results['Overall']['samples']['General'] = {}\n",
    "rounds_results['PerTrafficStream']['groundtruth']['DominantAssumption'] = {}\n",
    "rounds_results['PerTrafficStream']['groundtruth']['General'] = {}\n",
    "rounds_results['PerTrafficStream']['samples']['DominantAssumption'] = {}\n",
    "rounds_results['PerTrafficStream']['samples']['General'] = {}\n",
    "for flow in endToEnd_dfs.keys():\n",
    "    rounds_results['Overall']['groundtruth']['DominantAssumption'][flow] = 0\n",
    "    rounds_results['Overall']['groundtruth']['General'][flow] = 0\n",
    "    rounds_results['Overall']['samples']['DominantAssumption'][flow] = 0\n",
    "    rounds_results['Overall']['samples']['General'][flow] = 0\n",
    "    rounds_results['PerTrafficStream']['groundtruth']['DominantAssumption'][flow] = 0\n",
    "    rounds_results['PerTrafficStream']['groundtruth']['General'][flow] = 0\n",
    "    rounds_results['PerTrafficStream']['samples']['DominantAssumption'][flow] = 0\n",
    "    rounds_results['PerTrafficStream']['samples']['General'][flow] = 0\n",
    "\n",
    "for experiment in range(experiments):\n",
    "# for experiment in range(1):\n",
    "    # Reading the Groundtruth\n",
    "    file_paths = glob.glob('{}/scratch/Results/50Mbps/{}/*_EndToEnd.csv'.format(__ns3_path, experiment))\n",
    "    endToEnd_dfs = {}\n",
    "    for file_path in file_paths:\n",
    "        df_name = file_path.split('/')[-1].split('_')[0]\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df[df['IsReceived'] == 1]\n",
    "        df = df.reset_index(drop=True)\n",
    "        df = df[df['SentTime'] > steadyStart * 1000000000]\n",
    "        df = df[df['SentTime'] < steadyEnd * 1000000000]\n",
    "        df = df.drop(columns=['IsReceived'])\n",
    "        endToEnd_dfs[df_name] = df\n",
    "    \n",
    "    file_paths = glob.glob('{}/scratch/Results/50Mbps/{}/*_Switch.csv'.format(__ns3_path, experiment))\n",
    "    switch_dfs = {}\n",
    "    for file_path in file_paths:\n",
    "        df_name = file_path.split('/')[-1].split('_')[0]\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df[df['IsSent'] == 1]\n",
    "        df = df.reset_index(drop=True)\n",
    "        df = df[df['ReceiveTime'] > steadyStart * 1000000000]\n",
    "        df = df[df['ReceiveTime'] < steadyEnd * 1000000000]\n",
    "        df = df.drop(columns=['IsSent'])\n",
    "        switch_dfs[df_name] = df\n",
    "\n",
    "    # Reading the Samples\n",
    "    file_paths = glob.glob('{}/scratch/Results/50Mbps/{}/*_PoissonSampler.csv'.format(__ns3_path, experiment))\n",
    "    samples_dfs = {}\n",
    "    for file_path in file_paths:\n",
    "        df_name = file_path.split('/')[-1].split('_')[0]\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df[df['IsDeparted'] == 1]\n",
    "        df = df.reset_index(drop=True)\n",
    "        df = df[df['SampleTime'] > steadyStart * 1000000000]\n",
    "        df = df[df['SampleTime'] < steadyEnd * 1000000000]\n",
    "        df = df.drop(columns=['IsDeparted'])\n",
    "        samples_dfs[df_name] = df\n",
    "\n",
    "    # Intermediate links groundtruth statistics\n",
    "    interLinks_statistics = {}\n",
    "    for flow in endToEnd_dfs.keys():\n",
    "        interLinks_statistics[flow] = {}\n",
    "        interLinks_statistics[flow][('source', 'T0')] = get_statistics(intermediateLink_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), endToEnd_dfs[flow], switch_dfs['T0']))\n",
    "        interLinks_statistics[flow][('T0', 'T1')] = get_statistics(intermediateLink_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T0'], switch_dfs['T1']))\n",
    "        interLinks_statistics[flow][('T1', 'dest')] = get_statistics(intermediateLink_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T1'], endToEnd_dfs[flow]))\n",
    "\n",
    "\n",
    "    # samples switches statistics\n",
    "    samples_statistics = {}\n",
    "    samples_statistics['Overall'] = {}\n",
    "    samples_statistics['PerTrafficStream'] = {}\n",
    "\n",
    "    for flow in endToEnd_dfs.keys():\n",
    "        samples_statistics['Overall'][flow] = {}\n",
    "        samples_statistics['Overall'][flow]['T0'] = get_statistics(get_switch_samples_delays(switch_dfs['T0'], samples_dfs['T0T1']))\n",
    "        samples_statistics['Overall'][flow]['T1'] = get_statistics(get_switch_samples_delays(switch_dfs['T1'], samples_dfs['T1.R' + flow.split('R')[-1]]))\n",
    "\n",
    "        samples_statistics['PerTrafficStream'][flow] = {}\n",
    "        samples_statistics['PerTrafficStream'][flow]['T0'] = get_statistics(switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T0'], True))\n",
    "        samples_statistics['PerTrafficStream'][flow]['T1'] = get_statistics(switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T1'], True))\n",
    "\n",
    "    # groundtruth switches statistics\n",
    "    groundtruth_statistics = {}\n",
    "    groundtruth_statistics['Overall'] = {}\n",
    "    groundtruth_statistics['PerTrafficStream'] = {}\n",
    "\n",
    "    for flow in endToEnd_dfs.keys():\n",
    "        groundtruth_statistics['Overall'][flow] = {}\n",
    "        groundtruth_statistics['Overall'][flow]['T0'] = get_statistics(switch_dfs['T0'])\n",
    "        groundtruth_statistics['Overall'][flow]['T1'] = get_statistics(switch_dfs['T1'])\n",
    "\n",
    "        groundtruth_statistics['PerTrafficStream'][flow] = {}\n",
    "        groundtruth_statistics['PerTrafficStream'][flow]['T0'] = get_statistics(switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T0'], False))\n",
    "        groundtruth_statistics['PerTrafficStream'][flow]['T1'] = get_statistics(switch_data(endToEnd_dfs[flow].drop(columns=['SentTime', 'ReceiveTime']), switch_dfs['T1'], False))\n",
    "\n",
    "    # endToEnd_statistics\n",
    "    endToEnd_statistics = {}\n",
    "    for flow in endToEnd_dfs.keys():\n",
    "        endToEnd_statistics[flow] = get_statistics(endToEnd_dfs[flow])\n",
    "\n",
    "    # End to End and Persegment Compatibility Check\n",
    "    results = {}\n",
    "    results['Overall'] = {}\n",
    "    results['PerTrafficStream'] = {}\n",
    "    results['Overall']['groundtruth'] = check_all_delayConsistency(endToEnd_statistics, groundtruth_statistics['Overall'], interLinks_statistics, confidenceValue)\n",
    "    results['Overall']['samples'] = check_all_delayConsistency(endToEnd_statistics, samples_statistics['Overall'], interLinks_statistics, confidenceValue)\n",
    "    results['PerTrafficStream']['groundtruth'] = check_all_delayConsistency(endToEnd_statistics, groundtruth_statistics['PerTrafficStream'], interLinks_statistics, confidenceValue)\n",
    "    results['PerTrafficStream']['samples'] = check_all_delayConsistency(endToEnd_statistics, samples_statistics['PerTrafficStream'], interLinks_statistics, confidenceValue)\n",
    "\n",
    "    for flow in endToEnd_dfs.keys():\n",
    "        if results['Overall']['groundtruth']['DominantAssumption'][flow]:\n",
    "            rounds_results['Overall']['groundtruth']['DominantAssumption'][flow] += 1\n",
    "        if results['Overall']['groundtruth']['General'][flow]:\n",
    "            rounds_results['Overall']['groundtruth']['General'][flow] += 1\n",
    "        if results['Overall']['samples']['DominantAssumption'][flow]:\n",
    "            rounds_results['Overall']['samples']['DominantAssumption'][flow] += 1\n",
    "        if results['Overall']['samples']['General'][flow]:\n",
    "            rounds_results['Overall']['samples']['General'][flow] += 1\n",
    "        if results['PerTrafficStream']['groundtruth']['DominantAssumption'][flow]:\n",
    "            rounds_results['PerTrafficStream']['groundtruth']['DominantAssumption'][flow] += 1\n",
    "        if results['PerTrafficStream']['groundtruth']['General'][flow]:\n",
    "            rounds_results['PerTrafficStream']['groundtruth']['General'][flow] += 1\n",
    "        if results['PerTrafficStream']['samples']['DominantAssumption'][flow]:\n",
    "            rounds_results['PerTrafficStream']['samples']['DominantAssumption'][flow] += 1\n",
    "        if results['PerTrafficStream']['samples']['General'][flow]:\n",
    "            rounds_results['PerTrafficStream']['samples']['General'][flow] += 1\n",
    "\n",
    "# rounds_results\n",
    "# convert the results to jason and save it in results.json\n",
    "import json\n",
    "with open('results/results.json', 'w') as f:\n",
    "    json.dump(rounds_results, f)\n",
    "print(rounds_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
